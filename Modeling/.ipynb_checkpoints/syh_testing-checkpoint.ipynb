{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opponent-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import datasets, linear_model,cluster\n",
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-kenya",
   "metadata": {},
   "source": [
    "### Raw Data Reading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lovely-receptor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data has: 98078 rows\n"
     ]
    }
   ],
   "source": [
    "raw_df = pd.read_csv(\"zip_housing.csv\")\n",
    "print(\"Raw data has: \" + str(len(raw_df)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-stations",
   "metadata": {},
   "source": [
    "#### Raw Data Processing: Drop all rows where (beds, baths_full, lot_size, building_size) has na, and fill baths_half with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "medium-stack",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped data has: 89200 rows\n"
     ]
    }
   ],
   "source": [
    "# Deleting unreasonable data\n",
    "dropped_df = raw_df.dropna(subset=['beds','baths_full']) \n",
    "dropped_df[['baths_half']] = dropped_df[['baths_half']].fillna(0)\n",
    "dropped_df[['garage']] = dropped_df[['garage']].fillna(0)\n",
    "count = 0\n",
    "df = pd.DataFrame()\n",
    "grouped_df = dropped_df.groupby(\"postal_code\")\n",
    "for name, group in grouped_df:\n",
    "    group['lot_size'].fillna(group['lot_size'].median(), inplace=True)\n",
    "    group['building_size'].fillna(group['building_size'].median(), inplace=True)\n",
    "    ##group[[\"lot_size\"]].fillna(group[[\"lot_size\"]].median(), inplace = True)\n",
    "    ##group[[\"building_size\"]].fillna(group[[\"building_size\"]].median(), inplace = True)\n",
    "    group\n",
    "    if(count == 0):\n",
    "        df = group\n",
    "        count += 1\n",
    "    else:\n",
    "        df = pd.concat([df, group])\n",
    "    ##print(\"After: \" + str(len(group)))\n",
    "\n",
    "df.dropna(subset=['lot_size','building_size'], inplace = True)\n",
    "print(\"Dropped data has: \" + str(len(dropped_df)) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "opposed-measurement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>prop_type</th>\n",
       "      <th>year_built</th>\n",
       "      <th>is_new_construction</th>\n",
       "      <th>beds</th>\n",
       "      <th>baths_full</th>\n",
       "      <th>baths_half</th>\n",
       "      <th>garage</th>\n",
       "      <th>price</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>building_size</th>\n",
       "      <th>line</th>\n",
       "      <th>neighborhoods</th>\n",
       "      <th>city</th>\n",
       "      <th>county</th>\n",
       "      <th>state_code</th>\n",
       "      <th>postal_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O1305476579</td>\n",
       "      <td>single_family</td>\n",
       "      <td>1913.0</td>\n",
       "      <td>f</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>470000</td>\n",
       "      <td>5721.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>7916 Alix Ave</td>\n",
       "      <td>['Florence-Graham', 'South LA']</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>90001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O2866856410</td>\n",
       "      <td>single_family</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>f</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400000</td>\n",
       "      <td>5387.0</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>1659 E 70th St</td>\n",
       "      <td>['South LA']</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>90001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O2823776981</td>\n",
       "      <td>condo</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>f</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>659000</td>\n",
       "      <td>5667.0</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>1364 E 58th Pl</td>\n",
       "      <td>['South LA']</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>90001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>O1174561323</td>\n",
       "      <td>single_family</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>f</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>477000</td>\n",
       "      <td>6043.0</td>\n",
       "      <td>2344.0</td>\n",
       "      <td>7537 Maie Ave</td>\n",
       "      <td>['South LA']</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>90001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>O1387647983</td>\n",
       "      <td>multi_family</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>f</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600000</td>\n",
       "      <td>4365.0</td>\n",
       "      <td>2616.0</td>\n",
       "      <td>8308 Hooper Ave</td>\n",
       "      <td>['South LA']</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>90001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98069</th>\n",
       "      <td>O2043713036</td>\n",
       "      <td>mobile</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>f</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250000</td>\n",
       "      <td>27443.0</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>18556 Rex Ln</td>\n",
       "      <td>['Oasis', 'North Redding']</td>\n",
       "      <td>Redding</td>\n",
       "      <td>Shasta</td>\n",
       "      <td>CA</td>\n",
       "      <td>96003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98070</th>\n",
       "      <td>O2888448461</td>\n",
       "      <td>single_family</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>f</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300000</td>\n",
       "      <td>14375.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>1999 Salzburg Trl</td>\n",
       "      <td>['Northeast Redding', 'North Shasta View', 'Ta...</td>\n",
       "      <td>Redding</td>\n",
       "      <td>Shasta</td>\n",
       "      <td>CA</td>\n",
       "      <td>96003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98073</th>\n",
       "      <td>O1392454616</td>\n",
       "      <td>single_family</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>f</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275000</td>\n",
       "      <td>2614.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>2365 LA Villa Way</td>\n",
       "      <td>['Northeast Redding', 'The Villages at Shasta ...</td>\n",
       "      <td>Redding</td>\n",
       "      <td>Shasta</td>\n",
       "      <td>CA</td>\n",
       "      <td>96003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98075</th>\n",
       "      <td>O1290952370</td>\n",
       "      <td>single_family</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>f</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>483500</td>\n",
       "      <td>89734.0</td>\n",
       "      <td>2552.0</td>\n",
       "      <td>19287 Roxie Ln</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Redding</td>\n",
       "      <td>Shasta</td>\n",
       "      <td>CA</td>\n",
       "      <td>96003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98076</th>\n",
       "      <td>O1523744489</td>\n",
       "      <td>single_family</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>f</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>345000</td>\n",
       "      <td>87120.0</td>\n",
       "      <td>2040.0</td>\n",
       "      <td>13143 Tamera Way</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Redding</td>\n",
       "      <td>Shasta</td>\n",
       "      <td>CA</td>\n",
       "      <td>96003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89193 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       property_id      prop_type  year_built is_new_construction  beds  \\\n",
       "1      O1305476579  single_family      1913.0                   f   3.0   \n",
       "3      O2866856410  single_family      1905.0                   f   4.0   \n",
       "4      O2823776981          condo      1912.0                   f   5.0   \n",
       "5      O1174561323  single_family      1920.0                   f   5.0   \n",
       "6      O1387647983   multi_family      1971.0                   f   8.0   \n",
       "...            ...            ...         ...                 ...   ...   \n",
       "98069  O2043713036         mobile      1976.0                   f   3.0   \n",
       "98070  O2888448461  single_family      2007.0                   f   3.0   \n",
       "98073  O1392454616  single_family      2006.0                   f   3.0   \n",
       "98075  O1290952370  single_family      1977.0                   f   3.0   \n",
       "98076  O1523744489  single_family      1984.0                   f   4.0   \n",
       "\n",
       "       baths_full  baths_half  garage   price  lot_size  building_size  \\\n",
       "1             1.0         1.0     1.0  470000    5721.0         1030.0   \n",
       "3             2.0         0.0     0.0  400000    5387.0         1248.0   \n",
       "4             2.0         0.0     0.0  659000    5667.0         1897.0   \n",
       "5             5.0         0.0     0.0  477000    6043.0         2344.0   \n",
       "6             4.0         0.0     0.0  600000    4365.0         2616.0   \n",
       "...           ...         ...     ...     ...       ...            ...   \n",
       "98069         2.0         0.0     0.0  250000   27443.0         1248.0   \n",
       "98070         2.0         1.0     2.0  300000   14375.0         1687.0   \n",
       "98073         2.0         1.0     0.0  275000    2614.0         1430.0   \n",
       "98075         2.0         0.0     5.0  483500   89734.0         2552.0   \n",
       "98076         3.0         0.0     4.0  345000   87120.0         2040.0   \n",
       "\n",
       "                    line                                      neighborhoods  \\\n",
       "1          7916 Alix Ave                    ['Florence-Graham', 'South LA']   \n",
       "3         1659 E 70th St                                       ['South LA']   \n",
       "4         1364 E 58th Pl                                       ['South LA']   \n",
       "5          7537 Maie Ave                                       ['South LA']   \n",
       "6        8308 Hooper Ave                                       ['South LA']   \n",
       "...                  ...                                                ...   \n",
       "98069       18556 Rex Ln                         ['Oasis', 'North Redding']   \n",
       "98070  1999 Salzburg Trl  ['Northeast Redding', 'North Shasta View', 'Ta...   \n",
       "98073  2365 LA Villa Way  ['Northeast Redding', 'The Villages at Shasta ...   \n",
       "98075     19287 Roxie Ln                                                NaN   \n",
       "98076   13143 Tamera Way                                                NaN   \n",
       "\n",
       "              city       county state_code  postal_code  \n",
       "1      Los Angeles  Los Angeles         CA        90001  \n",
       "3      Los Angeles  Los Angeles         CA        90001  \n",
       "4      Los Angeles  Los Angeles         CA        90001  \n",
       "5      Los Angeles  Los Angeles         CA        90001  \n",
       "6      Los Angeles  Los Angeles         CA        90001  \n",
       "...            ...          ...        ...          ...  \n",
       "98069      Redding       Shasta         CA        96003  \n",
       "98070      Redding       Shasta         CA        96003  \n",
       "98073      Redding       Shasta         CA        96003  \n",
       "98075      Redding       Shasta         CA        96003  \n",
       "98076      Redding       Shasta         CA        96003  \n",
       "\n",
       "[89193 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-sympathy",
   "metadata": {},
   "source": [
    "Since our dataset is large enough, and we do not have much professional knowledge about property markets, we decided to ignore all rows that contain null values instead of filling in estimate values (mean or median)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-screen",
   "metadata": {},
   "source": [
    "## DBSCAN Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-sunglasses",
   "metadata": {},
   "source": [
    "#### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "concrete-heading",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4ed941f61662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscaled_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropped_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdropped_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscaled_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mscaled_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscaled_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1902\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'%d' is not a supported axis\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1904\u001b[0;31m     X = check_array(X, accept_sparse=sparse_format, copy=copy,\n\u001b[0m\u001b[1;32m   1905\u001b[0m                     estimator='the normalize function', dtype=FLOAT_DTYPES)\n\u001b[1;32m   1906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "scaled_dataset = dropped_df[dropped_df.columns[4:11]]\n",
    "scaled_dataset = preprocessing.normalize(scaled_dataset)\n",
    "scaled_dataset = pd.DataFrame(scaled_dataset)\n",
    "scaled_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-fifteen",
   "metadata": {},
   "source": [
    "#### Finding Best DBSCAN (eps and Minpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-corpus",
   "metadata": {},
   "source": [
    "Minpoints is suggested as 2*dimension which should be 14 in our case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = NearestNeighbors(n_neighbors = 14)\n",
    "neighbors_fit = neighbors.fit(scaled_dataset)\n",
    "distances, indices = neighbors_fit.kneighbors(scaled_dataset)\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-delhi",
   "metadata": {},
   "source": [
    "#### Zoom in to find 'elbow' optimization point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(distances)\n",
    "plt.axis([74000, 80000, 0.0002, 0.0010])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-administration",
   "metadata": {},
   "source": [
    "#### Fit DBSCAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "minpts = 14\n",
    "e = 0.0006\n",
    "db = cluster.DBSCAN(eps=e,min_samples=minpts, metric='euclidean', \n",
    "                    metric_params=None, algorithm='auto', \n",
    "                    leaf_size=30, p=None, n_jobs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-optimization",
   "metadata": {},
   "source": [
    "#### Get Labels: 0 for 'not outliers'; 1 for 'outliers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = db.fit(scaled_dataset)\n",
    "labels = []\n",
    "outliers = 0\n",
    "for i in model.labels_:\n",
    "    if i == -1:\n",
    "        labels.append(1)\n",
    "        outliers += 1\n",
    "    else:\n",
    "        labels.append(0)\n",
    "print(\"Found total: \" + str(outliers) + \" outliers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-overall",
   "metadata": {},
   "source": [
    "#### Combine Outliers and Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_df['outliers'] = labels\n",
    "noise_free_df = dropped_df[dropped_df['outliers'] == 0]\n",
    "print(\"Noise free data has: \" + str(len(noise_free_df)) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Highest Price: ' + str(max(noise_free_df['price'])))\n",
    "print('Largest Lot:   ' + str(max(noise_free_df['lot_size'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-colon",
   "metadata": {},
   "source": [
    "After all processing before, we still have the noise like (price == 915,000,000, or lot_size == 4,356,000,000) which we do not want in our processed dataset. The reason for this may because of the inner work of DBSCAN, which is unsupervised clustering. This raw dataset may contain enough data for those extrodinary large values to become an individual cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-quantity",
   "metadata": {},
   "source": [
    "### End of DBSCAN Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-anime",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-tracker",
   "metadata": {},
   "source": [
    "## IQR (interquantile range) Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-guest",
   "metadata": {},
   "source": [
    "#### Find IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr_dataset = dropped_df[dropped_df.columns[4:11]]\n",
    "Q1 = iqr_dataset.quantile(0.25)\n",
    "Q3 = iqr_dataset.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = Q1 - 1.5 * IQR\n",
    "higer = Q3 + 1.5 * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr_dataset_out = iqr_dataset[~((iqr_dataset < (lower)) |(iqr_dataset > (higer))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr_df = raw_df.iloc[list(iqr_dataset_out.index),:]\n",
    "iqr_df[['baths_half']] = iqr_df[['baths_half']].fillna(0)\n",
    "iqr_df[['garage']] = iqr_df[['garage']].fillna(0)\n",
    "print(\"IQR data has: \" + str(len(iqr_df)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-polish",
   "metadata": {},
   "source": [
    "### Result Graphs for IQR (Blue is original data; Orange is processed data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-boating",
   "metadata": {},
   "source": [
    "#### Building size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1)\n",
    "axs[0].plot(np.sort(dropped_df['building_size']))\n",
    "axs[1].plot(np.sort(iqr_dataset_out['building_size']), 'tab:orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-causing",
   "metadata": {},
   "source": [
    "#### Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1)\n",
    "axs[0].plot(np.sort(dropped_df['price']))\n",
    "axs[1].plot(np.sort(iqr_dataset_out['price']), 'tab:orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-circular",
   "metadata": {},
   "source": [
    "#### IQR method is considering all data as a whole. It is not based on any kind of clustering. Although we eliniminated a lot of extrodinary large values, we also eliniminated some reasonable data only because it is larger than the 75% quantile (price). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-print",
   "metadata": {},
   "source": [
    "### End of IQR method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-colleague",
   "metadata": {},
   "source": [
    "### Overall, I think the data processed by IQR method is much more reasonable than the DBSCAN method, but either case need to be further adjusted to fulfill our estimatation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
